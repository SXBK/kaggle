*原文地址：https://mlwave.com/kaggle-ensembling-guide/

*ensemble: 集合，集成
*stack: 堆叠

模型集成能够有效提高ML任务精度。
第一部分，根据提交文件创建集成
第二部分，通过堆叠泛化generalization/混合blending 创建集成

一、通过提交文件创建集成
1.投票集成
投票在低相关模型上能有效降低误差
eg，三个无关模型，精度均为70%，则投票后正确率约为78%
    五个时约为83%

kaggle用例：森林覆盖类型测试
对该任务，获得的最优单模型为ExtraTreesClassifier
加权
使用加权weighted多数投票-通常我们给予更好的模型更大的权重（最优3票，其余四个各1票）
原因：对于较次的模型，只有当他们都反对最优模型时才能否定最优模型

结果
单个最优：0.75571
投票集成（民主）：0.75337（下降）
投票集成（加权）：0.75667（提高）

kaggle用例：CIFAR-10图像识别
三十个convnets提交
单个最优：0.9317
投票集成：0.9412

2.平均
平均在很多问题（分类、回归问题）以及度量（AUC，均方误差或对数损失）上工作的很好

求各模型预测值的均值，在kaggle上也叫 bagging提交。

##################################################################
Bootstrap（再取样）：有放回抽样

Bagging（Bootstrap Aggregating集合）：利用bootstrap取出的子样本集训练一个模型，然后取平均。若各子模型独立，能够显著降低方差variance。模型相同，不能降低方差，而bagging出的各模型有一定相关性，在两种极端情况之间，一定程度降低了方差，增强模型鲁棒性。

Boosting：贪心迭代算法，每次训练后，对失败样本加权，反复训练，得到训练序列。由于是序列化的最小化损失函数，偏差逐步下降，但各子模型强相关，不能降低方差，增强模型准确性即loss function。 如Adaptive Boosting。

##################################################################

平均预测经常能够降低过拟合。

kaggle用例：单词遇到爆米花
利用在线感知器达到95.2的AUC
使用随机权重初始4个感知器并获取其平均
感知器：    0.95288
随机感知器：0.95092
随机感知器：0.95128
随机感知器：0.95118
随机感知器：0.95072
随机感知器：0.95427（提高0.0014）

3.排序平均
当平均不同模型的输出时，不是所有预测其都有校准：有可能在较高、较低预测值时过于/不够自信，或在某些范围下预测值很杂乱clutter
极端情况下有如下两组输出：
1	0.35000056	0.57
2	0.35000002	0.04
3	0.35000098	0.96
4	0.35000111	0.99
先将其转化成排序，然后将排序归一化
1	0.35000056	1   ->    0.33
2	0.35000002	0   ->    0
3	0.35000098	2   ->    0.66
4	0.35000111	3   ->    1

历史排序
排序需要一个测试集，对于只对新样本预测一个值，需要将其与旧的测试集一起排序，增大了解的复杂度。

解决方法是使用历史排序，在旧的测试集中，寻找最接近值的排序

kaggle用例：获取最有价值顾客挑战
历史排序在排序、基于阈值的度量（比如AUC）和搜索引擎性能度量（k上平均精度）上表现良好

多个VW模型，分别平均和排序平均
Vowpal Wabbit：		0.59962
Average Bag:		0.60031
Rank average Bag:	0.60187


二、堆叠泛化、混合

Netflix
Netflix组织和推广了第一个数据科学竞赛。在电影推荐挑战中的参赛者大幅提高了集成的艺术。

相关的paper：
http://arxiv.org/pdf/0911.0460.pdf
http://elf-project.sourceforge.net/CombiningPredictionsForAccurateRecommenderSystems.pdf
http://www.netflixprize.com/assets/GrandPrize2009_BPC_BigChaos.pdf
提高kaggle必看


1.堆叠泛化
基本思想：使用一个基本分类器池，然后使用另一个分类器组合他们的预测，以降低泛化误差

假设你要进行2折（2-fold）堆叠：
·将训练集分成两部分：traina和trainb
·基于traina训练第一阶段模型，并对trainb做预测   pa （也可预测得ta）
·基于trainb训练同样模型，对traina做预测    pb （tb）
·最后基于整个训练及训练模型，并对测试集做预测  t （此步可替换为ta+tb /2）
·然后根据第一阶段模型的概率训练第二阶段模型（利用p-y生成各模型的权重，然后再将权重施加在t上获取最终结果）

2.混合
与堆叠泛化类似，更简单，更小得信息泄露的风险

不需要对训练及进行折外预测，创建一个小的留出集，比如训练集的10%。堆叠模型只在留出集上训练。

混合有几个优点：
简单
抵抗信息泄露：泛化阶段（第一阶段）和堆叠阶段（第二阶段）使用里不同的数据
不需要和队友设置相同随机种子来分享分折方式，模型随便方到blender中，由blender决定是否保留

缺点：
使用的数据少了
最终模型可能对留出集过拟合
堆叠时多折上交叉验证比使用小的留出集更加稳健

堆叠和混合，随便哪个都可以，甚至两个都要，在第三阶段结合两个模型

逻辑回归堆叠
使用逻辑回归做堆叠非常基础
https://github.com/emanuele/kaggle_pbr/blob/master/blend.py

第一阶段预测测试集时，可以一次预测全部然后平均，也可以k折。

kaggle用例：艾德的草稿纸
利用上面得script，用逻辑回归集成了8个模型（分别属于ET，RF，GBM），0.99409分，第一名。

使用非线性算法进行堆叠
对于堆叠常用的非线性算法有GBM，KNN，NN，FR and ET

多分类任务上仅用原始特征的非线性堆叠都能有令人惊讶的提升。显然第一阶段的预测提供丰富信息并获得最高的特征重要性。非线性算法找到了在原始特征和元-模型特征之间的有用的交互。

kaggle用例：TUT头朝向评估竞赛
多分类多标签分类挑战

3.特征权重线性堆叠
特征权重线性堆叠 使用模型预测堆叠工程的元-特征。期望堆叠模型学习在确定特征值下哪个基础模型是最佳预测器。为了使结果模型更快和直观，使用线性算法。

4.模型的二次线性堆叠
与3相似，但是4创造模型预测的结合。多种情况下，这均能提高成绩。
例如有名的 妇女护法决策 http://www.drivendata.org/competitions/6/

线性堆叠和二次线性堆叠可以同时使用，可能都能发挥作用。

‘当创建基础模型时，你不会提前知道其是否有助于最终的元模型，在两阶段情况下，更有限弱模型。
那为什么要调优这些弱模型？有可能是获取独立性，但直到最后你依然不知道哪些基础模型有帮助。所以最终阶段更会是线性（要求不要调优，或者单个参数带来稀疏性）‘

5.使用回归来堆叠分类或者反之亦然
堆叠允许对回归问题使用分类，反之亦然。例如，可以对二分问题尝试分位数回归基础模型，一个好的堆叠器应该能够从预测中获取信息，即使回归并不是最好的分类器

对回归问题使用分类器稍微复杂点。首先：将y离散化。将一个回归问题转化成多分类问题。

6.堆叠非监督特征学习
K-means聚类是一个说明问题的流行技术。
t-SNE：降低数据集的2-3个纬度并利用非线性堆叠。使用留出集比较安全。

7.在线堆叠
我花了大量时间去研究一个叫online stacking的想法：首先从一个哈希二值映射中创建一个小型的随机树。如果树预测正确则增加其收益，反之减少其收益。然后我们将收益最大的树，和收益最小树的预测作为特征。

三、一切皆为超参
在进行堆叠/混合/元-模型时，将所有行动认为是堆叠模型的超参数是合理的。

例如：
不标准化数据
标准值标准化数据
最大最小值标准化数据
都是可调的能够提高集成效果的额外参数。同样的，基础模型的数量可被认为是需要调优的参数。特征选择（最好的70%）或数据填充（将缺失值填0）是另一些元参数的例子。

随机网格搜索是算法参数调优的理想方法，同样可以应用到这些元参数的调优

四、模型选择
你可以通过结合多种集成模型来进一步优化成绩。
·一个特别的方法：在人工选择的优秀集成上使用平均、投票或者排序平均
·贪婪的前向模型选择。以3或几个基本模型开始，添加能使训练集成绩增加最多的模型。通过允许放回模型，一个模型可以被选择多次（加权）。
·遗传模型选择：使用遗传算法，利用CV值作为适应度评价函数。
·完全随机方法：创造了一百多个随机选择的集成模型（无放回）。然后选择成绩最好的模型

五、自动化
当为某比赛堆叠模型时，我很快获得了top10的成绩。通过增加更多基本模型和平均多个堆叠集成我的成绩持续提高。

当我利用6个堆叠器搞到把7个模型叠起来后，我感到一阵痛苦和忧郁。我能否复现这一切？这个复杂又缓慢笨重的傻逼模型超出了我机器学习快速简单的舒适域。

我花费了整个竞赛的剩下时间完成一个自动堆叠器。对基础模型，完全随机参数和完全随机的算法用来训练。写了一个与Scikit-learn的api协同工作的封装器负责训练分类模型VM，Sofia-ML,RGF,MLP和XGBoost。

对于堆叠器，脚本中使用了SVM，随机森林，超级随机树，GBM和XGBoost，完全随机的参数和基础模型的随机子集。

最终堆叠器平均了他们在训练集上的预测并获得很小的损失。

这个自动产生的堆叠器排名57/3000.而完全不需要调优。

上下文相关的暴力优化是完全随机网格搜索的不错替代

同时你可以看到自动融合的简要： https://github.com/MLWave/hodor-autoML

Otto分类竞赛的前两名集成了超过1000种模型
1. https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/14335/1st-place-winner-solution-gilberto-titericz-stanislav-semenov
2. http://blog.kaggle.com/2015/06/09/otto-product-classification-winners-interview-2nd-place-alexander-guschin/

六、为什么要创建这种怪物集成
你也许觉得集成上千个模型，计算几十个小时疯了吧。差不多吧……这些怪物多少有点用：
·赢一次kaggle
·就这种方法可以打败学术界大多数方法
·以此为基准，比较你的更简单的改进算法
·计算资源加强，集成更轻松
·集成的知识能够迁移到浅层模型上。
·不是所有的基础模型都要按时完成，从这个角度，集成介绍了一种优雅的降级：丢失一两个模型不会有重大影响
·自动大型集成有效控制了过拟合，加入了一定形式的正则化，并且不需要调优或选择。懒逼专用。
·这是当前提高机器学习算法性能最佳的方法之一。
·精度的提升在实际使用中意义重大


